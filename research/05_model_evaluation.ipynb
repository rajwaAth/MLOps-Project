{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c3c3d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53bdf0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\admin\\\\OneDrive\\\\Dokumen\\\\Portofolio\\\\Data Sceince (Python)\\\\End-to-end\\\\research'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "083ede68",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0d11d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\admin\\\\OneDrive\\\\Dokumen\\\\Portofolio\\\\Data Sceince (Python)\\\\End-to-end'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03ebe9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    data_test_path: Path\n",
    "    model_path: Path\n",
    "    metric_file: Path\n",
    "    all_params: dict\n",
    "    target_col: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab242dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from end_to_end_project.constants import *\n",
    "from end_to_end_project.utils.common import read_yaml, create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation\n",
    "        params = self.params.ElasticNet\n",
    "        schema = self.schema.TARGET_COLUMN\n",
    "\n",
    "        create_directories([config['root_dir']])\n",
    "\n",
    "        model_eval_config = ModelEvaluationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_test_path=config.data_test_path,\n",
    "            model_path=config.model_path,\n",
    "            metric_file=config.metric_file,\n",
    "            all_params=params,\n",
    "            target_col=schema.name\n",
    "        )\n",
    "\n",
    "        return model_eval_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdfb380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from urllib.parse import urlparse\n",
    "from dagshub import init\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import joblib\n",
    "from end_to_end_project.utils.common import save_json\n",
    "\n",
    "class ModelEvaluation:\n",
    "    def __init__(self, config: ModelEvaluationConfig):\n",
    "        self.config = config\n",
    "        init(repo_owner=\"rajwaAth\", repo_name='MLOps-Project', mlflow=True)\n",
    "\n",
    "    def eval_metrics(self, actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        mae = mean_absolute_error(actual, pred)\n",
    "        r2 = r2_score(actual, pred)\n",
    "        return rmse, mae, r2\n",
    "    \n",
    "    def log_into_mlflow(self):\n",
    "        test_data = pd.read_csv(self.config.data_test_path)\n",
    "        model = joblib.load(self.config.model_path)\n",
    "\n",
    "        X_test = test_data.drop(columns=[self.config.target_col])\n",
    "        y_test = test_data[self.config.target_col]\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "        rmse, mae, r2 = self.eval_metrics(y_test, pred)\n",
    "\n",
    "        scores = {\n",
    "            \"rmse\": rmse,\n",
    "            \"mae\": mae,\n",
    "            \"r2\": r2\n",
    "        }\n",
    "        save_json(path=Path(self.config.metric_file), data=scores)\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            for key, value in scores.items():\n",
    "                mlflow.log_metric(key, value)\n",
    "            mlflow.sklearn.log_model(model, \"model\", registered_model_name=\"ElasticNetModel\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0948cf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-02 23:15:07,858: INFO: common: YAML file: config\\config.yaml loaded successfully]\n",
      "[2025-08-02 23:15:07,866: INFO: common: YAML file: params.yaml loaded successfully]\n",
      "[2025-08-02 23:15:07,871: INFO: common: YAML file: schema.yaml loaded successfully]\n",
      "[2025-08-02 23:15:07,875: INFO: common: Created directory at: artifacts/model_evaluation]\n",
      "[2025-08-02 23:15:08,715: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/rajwaAth/MLOps-Project \"HTTP/1.1 200 OK\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"rajwaAth/MLOps-Project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"rajwaAth/MLOps-Project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-02 23:15:08,740: INFO: helpers: Initialized MLflow to track repo \"rajwaAth/MLOps-Project\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository rajwaAth/MLOps-Project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository rajwaAth/MLOps-Project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-02 23:15:08,744: INFO: helpers: Repository rajwaAth/MLOps-Project initialized!]\n",
      "[2025-08-02 23:15:08,849: INFO: common: JSON file saved at: artifacts\\model_evaluation\\metrics.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\envs\\n2nProject\\lib\\site-packages\\_distutils_hack\\__init__.py:15: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "c:\\Users\\admin\\anaconda3\\envs\\n2nProject\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_eval_config = config.get_model_evaluation_config()\n",
    "    model_eval = ModelEvaluation(config=model_eval_config)\n",
    "    model_eval.log_into_mlflow()\n",
    "except Exception as e:\n",
    "    raise e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47fc416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "n2nProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
